{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMj5rl7KLzzv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from lab3_proto import *\n",
        "#from proto2 import *\n",
        "from lab3_proto import *\n",
        "from lab3_tools import *\n",
        "from lab2_proto import *\n",
        "from lab2_tools import *\n",
        "from lab1_proto import *\n",
        "from lab1_tools import *\n",
        "from IPython.display import Audio,Image\n",
        "from scipy.signal import lfilter\n",
        "from prondict import *\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uBb27uTLzzw"
      },
      "source": [
        "first time setup: download tidigits to this folder using this link: https://drive.google.com/file/d/1UgY60Uek1OznD7VGRFyOiF_eqwSVvhM3/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ1NxGX7Lzzx",
        "outputId": "65266d34-e1f2-46c1-8d2b-2e21ef93cbc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('woman', 'ac', 'z849768', 'a')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path2info('tidigits/disc_4.1.1/tidigits/train/woman/ac/z849768a.wav') #'tidigits/disc_4.1.1/tidigits/train/man/ae/z9z6531a.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxlwnQGZLzzy",
        "outputId": "794bd019-5a2a-48a6-e579-b838130ca935"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('man', 'ae', 'z9z6531', 'a')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path2info('tidigits\\\\disc_4.1.1\\\\tidigits\\\\train\\\\man\\\\ae\\\\z9z6531a.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUp3jHoTLzzy",
        "outputId": "ef207a1f-5e03-41f0-9216-44c40ec0a6ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 8, 10, 10, ..., 14, 14, 10], dtype=int16), 20000)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import soundfile as sf\n",
        "loadAudio(\"C:\\\\Users\\\\A\\\\Desktop\\\\KTH\\\\dt2119_speech_recpgmotopm\\\\Speech-and-speaker-recognition\\\\lab3\\\\tidigits\\\\tidigits\\\\disc_4.1.1\\\\tidigits\\\\train\\\\man\\\\ae\\\\1a.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0V_9DlqnLzzz"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "base_path = Path(\"C:\\\\Users\\\\A\\\\Desktop\\\\KTH\\\\dt2119_speech_recpgmotopm\\\\Speech-and-speaker-recognition\\\\lab3\\\\tidigits\\\\\")\n",
        "filename = 'tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
        "filepath = base_path / Path(filename)\n",
        "samples, samplingrate = loadAudio(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLueJz_ELzzz",
        "outputId": "d6b5e2d4-7437-4e30-91e5-c6607d724fb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ah_0',\n",
              " 'ah_1',\n",
              " 'ah_2',\n",
              " 'ao_0',\n",
              " 'ao_1',\n",
              " 'ao_2',\n",
              " 'ay_0',\n",
              " 'ay_1',\n",
              " 'ay_2',\n",
              " 'eh_0',\n",
              " 'eh_1',\n",
              " 'eh_2',\n",
              " 'ey_0',\n",
              " 'ey_1',\n",
              " 'ey_2',\n",
              " 'f_0',\n",
              " 'f_1',\n",
              " 'f_2',\n",
              " 'ih_0',\n",
              " 'ih_1',\n",
              " 'ih_2',\n",
              " 'iy_0',\n",
              " 'iy_1',\n",
              " 'iy_2',\n",
              " 'k_0',\n",
              " 'k_1',\n",
              " 'k_2',\n",
              " 'n_0',\n",
              " 'n_1',\n",
              " 'n_2',\n",
              " 'ow_0',\n",
              " 'ow_1',\n",
              " 'ow_2',\n",
              " 'r_0',\n",
              " 'r_1',\n",
              " 'r_2',\n",
              " 's_0',\n",
              " 's_1',\n",
              " 's_2',\n",
              " 'sil_0',\n",
              " 'sil_1',\n",
              " 'sil_2',\n",
              " 'sp_0',\n",
              " 't_0',\n",
              " 't_1',\n",
              " 't_2',\n",
              " 'th_0',\n",
              " 'th_1',\n",
              " 'th_2',\n",
              " 'uw_0',\n",
              " 'uw_1',\n",
              " 'uw_2',\n",
              " 'v_0',\n",
              " 'v_1',\n",
              " 'v_2',\n",
              " 'w_0',\n",
              " 'w_1',\n",
              " 'w_2',\n",
              " 'z_0',\n",
              " 'z_1',\n",
              " 'z_2']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "phoneHMMs = np.load('lab2_models_all.npz',allow_pickle=True)['phoneHMMs'].item()\n",
        "phones = sorted(phoneHMMs.keys())\n",
        "nstates = {phone: phoneHMMs[phone]['means'].shape[0] for phone in phones}\n",
        "stateList = [ph + '_' + str(id) for ph in phones for id in range(nstates[ph])]\n",
        "stateList\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfrqZsfFLzzz",
        "outputId": "15e7fee3-9530-4563-add9-17e21d13664b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stateList.index('ay_2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq-HPs4cLzzz"
      },
      "source": [
        "## 4.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PIduyUoLzzz"
      },
      "outputs": [],
      "source": [
        "filename = 'tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
        "samples, samplingrate = loadAudio(base_path / Path(filename))\n",
        "\n",
        "lmfcc = mfcc(samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UD3z_XtFLzz0"
      },
      "outputs": [],
      "source": [
        "example = np.load(\"lab3_example.npz\",allow_pickle=True)['example'].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sI9ifJ6LLzz0"
      },
      "outputs": [],
      "source": [
        "filename = 'tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
        "samples, samplingrate = loadAudio(base_path / Path(filename))\n",
        "lmfcc = mfcc(samples)\n",
        "wordTrans = list(path2info(filename)[2])\n",
        "phoneTrans = words2phones(wordTrans,prondict)\n",
        "utteranceHMM = concatHMMs(phoneHMMs,phoneTrans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe2bk8-QLzz1",
        "outputId": "af67a9a1-4414-432b-804e-afc81a5e30e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(178, 13)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lmfcc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w--iy6e-Lzz1"
      },
      "outputs": [],
      "source": [
        "stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans\n",
        "              for stateid in range(nstates[phone])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gidIB53ILzz1",
        "outputId": "2463577c-a804-478a-d97b-7981243cb1f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'r_1'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stateTrans[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCtbwXxsLzz1",
        "outputId": "400c7bf6-5cb0-4d96-92d1-2b403ae96bd8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_14084\\1985007783.py:6: RuntimeWarning: divide by zero encountered in log\n",
            "  score,path=viterbi(log_likelihoods,np.log(Hmm[\"startprob\"]),np.log(Hmm[\"transmat\"]),False)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['sil_0',\n",
              " 'sil_1',\n",
              " 'sil_1',\n",
              " 'sil_1',\n",
              " 'sil_1',\n",
              " 'sil_1',\n",
              " 'sil_1',\n",
              " 'sil_1',\n",
              " 'sil_1',\n",
              " 'sil_1',\n",
              " 'sil_1',\n",
              " 'sil_1',\n",
              " 'sil_1',\n",
              " 'sil_1',\n",
              " 'sil_1',\n",
              " 'sil_1',\n",
              " 'sil_1',\n",
              " 'sil_1',\n",
              " 'sil_1',\n",
              " 'sil_2',\n",
              " 'z_0',\n",
              " 'z_0',\n",
              " 'z_0',\n",
              " 'z_0',\n",
              " 'z_1',\n",
              " 'z_2',\n",
              " 'z_2',\n",
              " 'z_2',\n",
              " 'z_2',\n",
              " 'z_2',\n",
              " 'z_2',\n",
              " 'z_2',\n",
              " 'z_2',\n",
              " 'z_2',\n",
              " 'z_2',\n",
              " 'z_2',\n",
              " 'iy_0',\n",
              " 'iy_0',\n",
              " 'iy_0',\n",
              " 'iy_0',\n",
              " 'iy_0',\n",
              " 'iy_0',\n",
              " 'iy_0',\n",
              " 'iy_0',\n",
              " 'iy_1',\n",
              " 'iy_2',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_1',\n",
              " 'r_2',\n",
              " 'ow_0',\n",
              " 'ow_1',\n",
              " 'ow_2',\n",
              " 'ow_2',\n",
              " 'ow_2',\n",
              " 'ow_2',\n",
              " 'ow_2',\n",
              " 'ow_2',\n",
              " 'ow_2',\n",
              " 'ow_2',\n",
              " 'ow_2',\n",
              " 'f_0',\n",
              " 'f_1',\n",
              " 'f_1',\n",
              " 'f_1',\n",
              " 'f_1',\n",
              " 'f_1',\n",
              " 'f_1',\n",
              " 'f_1',\n",
              " 'f_1',\n",
              " 'f_1',\n",
              " 'f_1',\n",
              " 'f_1',\n",
              " 'f_2',\n",
              " 'ao_0',\n",
              " 'ao_1',\n",
              " 'ao_1',\n",
              " 'ao_1',\n",
              " 'ao_1',\n",
              " 'ao_1',\n",
              " 'ao_1',\n",
              " 'ao_1',\n",
              " 'ao_1',\n",
              " 'ao_1',\n",
              " 'ao_1',\n",
              " 'ao_1',\n",
              " 'ao_1',\n",
              " 'ao_1',\n",
              " 'ao_1',\n",
              " 'ao_2',\n",
              " 'ao_2',\n",
              " 'ao_2',\n",
              " 'ao_2',\n",
              " 'ao_2',\n",
              " 'ao_2',\n",
              " 'ao_2',\n",
              " 'ao_2',\n",
              " 'ao_2',\n",
              " 'ao_2',\n",
              " 'ao_2',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_1',\n",
              " 'r_2',\n",
              " 'th_0',\n",
              " 'th_0',\n",
              " 'th_0',\n",
              " 'th_0',\n",
              " 'th_0',\n",
              " 'th_0',\n",
              " 'th_0',\n",
              " 'th_0',\n",
              " 'th_0',\n",
              " 'th_0',\n",
              " 'th_1',\n",
              " 'th_1',\n",
              " 'th_1',\n",
              " 'th_2',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_0',\n",
              " 'r_1',\n",
              " 'r_2',\n",
              " 'iy_0',\n",
              " 'iy_0',\n",
              " 'iy_0',\n",
              " 'iy_0',\n",
              " 'iy_0',\n",
              " 'iy_0',\n",
              " 'iy_0',\n",
              " 'iy_0',\n",
              " 'iy_0',\n",
              " 'iy_0',\n",
              " 'iy_1',\n",
              " 'iy_1',\n",
              " 'iy_2',\n",
              " 'iy_2',\n",
              " 'iy_2',\n",
              " 'iy_2',\n",
              " 'iy_2',\n",
              " 'iy_2',\n",
              " 'iy_2',\n",
              " 'iy_2',\n",
              " 'sil_0',\n",
              " 'sil_0',\n",
              " 'sil_0',\n",
              " 'sil_0',\n",
              " 'sil_0',\n",
              " 'sil_0',\n",
              " 'sil_0',\n",
              " 'sil_0',\n",
              " 'sil_0',\n",
              " 'sil_0',\n",
              " 'sil_0',\n",
              " 'sil_0',\n",
              " 'sil_0',\n",
              " 'sil_0',\n",
              " 'sil_0',\n",
              " 'sil_0',\n",
              " 'sil_0',\n",
              " 'sil_0',\n",
              " 'sil_1',\n",
              " 'sil_2']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#align the states in the utteranceHMM model to the sequence of feature vectors in lmfcc\n",
        "\n",
        "X0 = lmfcc\n",
        "Hmm = utteranceHMM\n",
        "log_likelihoods=log_multivariate_normal_density_diag(X0,Hmm[\"means\"],Hmm[\"covars\"])\n",
        "score,path=viterbi(log_likelihoods,np.log(Hmm[\"startprob\"]),np.log(Hmm[\"transmat\"]),False)\n",
        "state_seq = []\n",
        "for i in range(len(path)):\n",
        "    state_seq.append(stateTrans[path[i]])\n",
        "state_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzV4_hmyLzz2",
        "outputId": "4f10c91b-5577-43f0-e2af-ecea8b06c1ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  2,  3,  3,  3,  3,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
              "        5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  7,  8,  9,  9,  9,  9,  9,\n",
              "        9,  9,  9,  9,  9, 10, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14,\n",
              "       14, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 19, 20, 20,\n",
              "       20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21,\n",
              "       21, 21, 21, 21, 21, 21, 22, 22, 22, 23, 24, 26, 26, 26, 26, 26, 26,\n",
              "       26, 26, 26, 26, 27, 27, 27, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
              "       30, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 34, 34, 34,\n",
              "       34, 34, 34, 34, 34, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
              "       36, 36, 36, 36, 36, 36, 37, 38], dtype=int64)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p44_qfuDLzz3",
        "outputId": "71e649ff-2294-4c07-f42e-1a46f649bb2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'0 0.01 sil_0\\n0.01 0.19000000000000003 sil_1\\n0.19000000000000003 0.20000000000000004 sil_2\\n0.20000000000000004 0.24000000000000007 z_0\\n0.24000000000000007 0.25000000000000006 z_1\\n0.25000000000000006 0.36000000000000015 z_2\\n0.36000000000000015 0.4400000000000002 iy_0\\n0.4400000000000002 0.45000000000000023 iy_1\\n0.45000000000000023 0.46000000000000024 iy_2\\n0.46000000000000024 0.5600000000000003 r_0\\n0.5600000000000003 0.5700000000000003 r_1\\n0.5700000000000003 0.5800000000000003 r_2\\n0.5800000000000003 0.5900000000000003 ow_0\\n0.5900000000000003 0.6000000000000003 ow_1\\n0.6000000000000003 0.6900000000000004 ow_2\\n0.6900000000000004 0.7000000000000004 f_0\\n0.7000000000000004 0.8100000000000005 f_1\\n0.8100000000000005 0.8200000000000005 f_2\\n0.8200000000000005 0.8300000000000005 ao_0\\n0.8300000000000005 0.9700000000000006 ao_1\\n0.9700000000000006 1.0800000000000007 ao_2\\n1.0800000000000007 1.1100000000000008 r_0\\n1.1100000000000008 1.1200000000000008 r_1\\n1.1200000000000008 1.1300000000000008 r_2\\n1.1300000000000008 1.2300000000000009 th_0\\n1.2300000000000009 1.260000000000001 th_1\\n1.260000000000001 1.270000000000001 th_2\\n1.270000000000001 1.360000000000001 r_0\\n1.360000000000001 1.370000000000001 r_1\\n1.370000000000001 1.380000000000001 r_2\\n1.380000000000001 1.480000000000001 iy_0\\n1.480000000000001 1.500000000000001 iy_1\\n1.500000000000001 1.5800000000000012 iy_2\\n1.5800000000000012 1.7600000000000013 sil_0\\n1.7600000000000013 1.7700000000000014 sil_1\\n1.7700000000000014 1.7800000000000014 sil_2\\n'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#take state_seq and create a transcription file based on it\n",
        "#[sil_0,sil_1,sil_1,z_0,z_1,z_2...] -> \"z\" at 40 ms\n",
        "frames2trans(state_seq, outfilename='z43a.lab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk9wzxDiLzz3"
      },
      "source": [
        "the alignment is mostly good but some parts bleed in to each other e.g. \"r\" in four"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3n_U4TPLzz3"
      },
      "source": [
        "## 4.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBN2ZU4ALzz3",
        "outputId": "df6125b5-86c4-4afe-9cdf-7eaa914f09fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stateList.index(\"ah_0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwrWmy6VLzz3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "if not Path(\"traindata.npz\").exists():\n",
        "    traindata = []\n",
        "    for root, dirs, files in os.walk(base_path / 'tidigits/disc_4.1.1/tidigits/train'):\n",
        "        for file in files:\n",
        "            if file.endswith('.wav'):\n",
        "                filename = os.path.join(root, file)\n",
        "                samples, samplingrate = loadAudio(filename)\n",
        "\n",
        "                mspec_vals = mspec(samples)\n",
        "\n",
        "                lmfcc = mfcc(samples)\n",
        "                wordTrans = list(path2info(filename)[2])\n",
        "                #phoneHMM har vi redan\n",
        "                phoneTrans = words2phones(wordTrans,prondict)\n",
        "                utteranceHMM = concatHMMs(phoneHMMs,phoneTrans)\n",
        "                stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans\n",
        "                                for stateid in range(nstates[phone])]\n",
        "                Hmm = utteranceHMM\n",
        "                log_likelihoods=log_multivariate_normal_density_diag(lmfcc,Hmm[\"means\"],Hmm[\"covars\"])\n",
        "                score,path=viterbi(log_likelihoods,np.log(Hmm[\"startprob\"]),np.log(Hmm[\"transmat\"]),False)\n",
        "\n",
        "                state_seq = []\n",
        "                for i in range(len(path)):\n",
        "                    state_seq.append(stateTrans[path[i]])\n",
        "\n",
        "\n",
        "                traindata.append({'filename': filename, 'lmfcc': lmfcc,\n",
        "                    'mspec': mspec_vals, 'targets': state_seq})\n",
        "    np.savez('traindata.npz', traindata=traindata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32OxzIanLzz4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufPUOmFkLzz4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not Path(\"testdata.npz\").exists():\n",
        "    testdata = []\n",
        "    for root, dirs, files in os.walk(base_path / 'tidigits/disc_4.2.1/tidigits/test'):\n",
        "        for file in files:\n",
        "            if file.endswith('.wav'):\n",
        "                filename = os.path.join(root, file)\n",
        "                samples, samplingrate = loadAudio(filename)\n",
        "\n",
        "                mspec_vals = mspec(samples)\n",
        "\n",
        "                lmfcc = mfcc(samples)\n",
        "                wordTrans = list(path2info(filename)[2])\n",
        "                phoneTrans = words2phones(wordTrans,prondict)\n",
        "                utteranceHMM = concatHMMs(phoneHMMs,phoneTrans)\n",
        "                stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans\n",
        "                                for stateid in range(nstates[phone])]\n",
        "                Hmm = utteranceHMM\n",
        "                log_likelihoods=log_multivariate_normal_density_diag(lmfcc,Hmm[\"means\"],Hmm[\"covars\"])\n",
        "                score,path=viterbi(log_likelihoods,np.log(Hmm[\"startprob\"]),np.log(Hmm[\"transmat\"]),False)\n",
        "\n",
        "                state_seq = []\n",
        "                for i in range(len(path)):\n",
        "                    state_seq.append(stateTrans[path[i]])\n",
        "\n",
        "\n",
        "                testdata.append({'filename': filename, 'lmfcc': lmfcc,\n",
        "                    'mspec': mspec_vals, 'targets': state_seq})\n",
        "    np.savez('testdata.npz', testdata=testdata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSUS9WoQLzz4"
      },
      "outputs": [],
      "source": [
        "traindata = np.load(\"traindata.npz\",allow_pickle=True)['traindata']\n",
        "testdata = np.load(\"testdata.npz\",allow_pickle=True)['testdata']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8SleRPLLzz4"
      },
      "source": [
        "## 4.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLB4lUc_Lzz4",
        "outputId": "8d3f71dd-2484-4173-adb7-cca2ad335a4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4235, 4388)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "males = []\n",
        "females = []\n",
        "for i in range(len(traindata)):\n",
        "    speaker_gender = path2info(traindata[i][\"filename\"])[0]\n",
        "    if speaker_gender == \"man\":\n",
        "        males.append(traindata[i])\n",
        "    else:\n",
        "        females.append(traindata[i])\n",
        "len(males),len(females)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwc-YM-MLzz5"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "train_size_male = int(0.9 * len(males))\n",
        "train_size_female = int(0.9 * len(females))\n",
        "\n",
        "random.shuffle(males)\n",
        "random.shuffle(females)\n",
        "#extract the amount of males we need\n",
        "train_males = males[:train_size_male]\n",
        "val_males = males[train_size_male:]\n",
        "#females we need\n",
        "train_females = females[:train_size_female]\n",
        "val_females = females[train_size_female:]\n",
        "#merge them\n",
        "train_data = train_males + train_females\n",
        "val_data = val_males + val_females\n",
        "#shuffle again to avoid it being MMMM...FFFF... instead MFMFFMFM...\n",
        "random.shuffle(train_data)\n",
        "random.shuffle(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LeQSWP5Lzz5",
        "outputId": "23794d9b-b127-4836-cd5e-cdbe94678ba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "male to female ratio is 0.9650544441630793\n",
            "male to female ratio is 0.9658314350797267\n"
          ]
        }
      ],
      "source": [
        "#check gender ratio\n",
        "for k in [train_data,val_data]:\n",
        "    male = 0\n",
        "    female = 0\n",
        "    for i in range(len(k)):\n",
        "        speaker_gender = path2info(k[i][\"filename\"])[0]\n",
        "        if speaker_gender == \"man\":\n",
        "            male += 1\n",
        "        else:\n",
        "            female +=1\n",
        "    print(f\"male to female ratio is {male/female}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkwDMApfLzz5"
      },
      "outputs": [],
      "source": [
        "traindata=train_data\n",
        "valdata=val_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttFHa_jaLzz5"
      },
      "source": [
        "## 4.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUOc7j1kLzz6"
      },
      "outputs": [],
      "source": [
        "def get_indices(i,length):\n",
        "    idx_list = list(range(length))\n",
        "    idx_list = idx_list[1:4][::-1] + idx_list + idx_list[-4:-1][::-1]\n",
        "    return idx_list[i:i + 7]\n",
        "for dataset in [traindata, valdata,testdata]:\n",
        "    for i in range(len(dataset)):\n",
        "        #Tx91, where T is number of frames in the datapoint\n",
        "        datapoint_dynamic = np.zeros((len(dataset[i][\"lmfcc\"]),7*dataset[i][\"lmfcc\"].shape[1]))#a new matrix that stores the stacked (dynamic) data of dataset[i]\n",
        "        for t in range(len(dataset[i])):\n",
        "            indxs = get_indices(t,len(dataset[i]))\n",
        "            for k in indxs:\n",
        "                datapoint_dynamic[t,13*k:13*(k+1)] = dataset[i][\"lmfcc\"][k] #1x13\n",
        "\n",
        "        dataset[i][\"lmfcc_dynamic\"] = datapoint_dynamic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tp_NbmORLzz6",
        "outputId": "d9b3d749-9f72-4a58-864e-0106c6bbe9e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((210, 91), (210, 13))"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "traindata[2][\"lmfcc_dynamic\"].shape,traindata[2][\"lmfcc\"].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xm7BkSLLzz6"
      },
      "source": [
        "create dynamic version of mspec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zM2iqpeBLzz6"
      },
      "outputs": [],
      "source": [
        "for dataset in [traindata, valdata,testdata]:\n",
        "    for i in range(len(dataset)):\n",
        "        #Tx91, where T is number of frames in the datapoint\n",
        "        datapoint_dynamic = np.zeros((len(dataset[i][\"mspec\"]),7*dataset[i][\"mspec\"].shape[1]))#a new matrix that stores the stacked (dynamic) data of dataset[i]\n",
        "        for t in range(len(dataset[i])):\n",
        "            indxs = get_indices(t,len(dataset[i]))\n",
        "            for k in indxs:\n",
        "                datapoint_dynamic[t,40*k:40*(k+1)] = dataset[i][\"mspec\"][k] #1x13\n",
        "\n",
        "        dataset[i][\"mspec_dynamic\"] = datapoint_dynamic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBy4zCQWLzz6"
      },
      "source": [
        "create our big matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_ZxTMAPLzz6"
      },
      "outputs": [],
      "source": [
        "lmfcc_train_x=np.concatenate([d[\"lmfcc\"] for d in traindata]).astype('float32')\n",
        "lmfcc_val_x=np.concatenate([d[\"lmfcc\"] for d in valdata]).astype('float32')\n",
        "lmfcc_test_x=np.concatenate([d[\"lmfcc\"] for d in testdata]).astype('float32')\n",
        "\n",
        "lmfcc_train_x_dynamic = np.concatenate([d[\"lmfcc_dynamic\"] for d in traindata]).astype('float32')\n",
        "lmfcc_val_x_dynamic=np.concatenate([d[\"lmfcc_dynamic\"] for d in valdata]).astype('float32')\n",
        "lmfcc_test_x_dynamic=np.concatenate([d[\"lmfcc_dynamic\"] for d in testdata]).astype('float32')\n",
        "\n",
        "\n",
        "mspec_train_x = np.concatenate([d[\"mspec\"] for d in traindata]).astype('float32')\n",
        "mspec_val_x = np.concatenate([d[\"mspec\"] for d in valdata]).astype('float32')\n",
        "mspec_test_x = np.concatenate([d[\"mspec\"] for d in testdata]).astype('float32')\n",
        "\n",
        "\n",
        "mspec_train_x_dynamic = np.concatenate([d[\"mspec_dynamic\"] for d in traindata]).astype('float32')\n",
        "mspec_val_x_dynamic = np.concatenate([d[\"mspec_dynamic\"] for d in valdata]).astype('float32')\n",
        "mspec_test_x_dynamic = np.concatenate([d[\"mspec_dynamic\"] for d in testdata]).astype('float32')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leqSBHcqLzz7",
        "outputId": "a5812056-ea39-41c6-c6e1-d331223ac32e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1354354,)\n",
            "(153038,)\n",
            "(1527014,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "train_y = np.concatenate([[stateList.index(targ) for targ in d[\"targets\"]] for d in traindata]).flatten()\n",
        "print(train_y.shape)\n",
        "val_y = np.concatenate([[stateList.index(targ) for targ in d[\"targets\"]] for d in valdata]).flatten()\n",
        "print(val_y.shape)\n",
        "test_y = np.concatenate([[stateList.index(targ) for targ in d[\"targets\"]] for d in testdata]).flatten()\n",
        "print(test_y.shape)\n",
        "\n",
        "output_dim = len(stateList)\n",
        "\n",
        "train_y = F.one_hot(torch.tensor(train_y, dtype=torch.long),num_classes=output_dim)\n",
        "val_y = F.one_hot(torch.tensor(val_y, dtype=torch.long),num_classes=output_dim)\n",
        "test_y = F.one_hot(torch.tensor(test_y, dtype=torch.long),num_classes=output_dim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuzSXP2ILzz7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#experiment 1\n",
        "train_x = mspec_train_x\n",
        "val_x = mspec_val_x\n",
        "test_x = mspec_test_x\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self,input_size):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        # Define layers here, for example:\n",
        "        # A fully connected layer from input of size to a hidden layer of size 256\n",
        "        self.fc1 = nn.Linear(input_size, 256)\n",
        "        # Define the second hidden layer\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        # Define the third hidden layer\n",
        "        self.fc3 = nn.Linear(256, 256)\n",
        "        # Define the fourth hidden layer\n",
        "        self.fc4 = nn.Linear(256, output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define the forward pass\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)  # Apply ReLU activation after first layer\n",
        "        x = self.fc2(x)          # Output layer\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "    def count_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I49jiw5wLzz7",
        "outputId": "3b7b4a48-e762-4e2b-aae3-7e6044206e90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157757\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SimpleNet(\n",
              "  (fc1): Linear(in_features=40, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (fc3): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (fc4): Linear(in_features=256, out_features=61, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = SimpleNet(40)\n",
        "print(net.count_parameters())\n",
        "optimizer = torch.optim.Adam(net.parameters())\n",
        "batch_size = 256\n",
        "net.to(torch.device(\"cuda\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHw7B-NxLzz7",
        "outputId": "dab5647a-b6d2-4f7b-e456-149a77618987"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_14084\\636988354.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_y = torch.tensor(train_y)\n",
            "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_14084\\636988354.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_y = torch.tensor(val_y)\n",
            "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_14084\\636988354.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_y = torch.tensor(test_y)\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "train_x = torch.tensor(train_x)\n",
        "train_y = torch.tensor(train_y)\n",
        "val_x = torch.tensor(val_x)\n",
        "val_y = torch.tensor(val_y)\n",
        "test_x = torch.tensor(test_x)\n",
        "test_y = torch.tensor(test_y)\n",
        "\n",
        "# create the data loaders for training and validation sets\n",
        "train_dataset = torch.utils.data.TensorDataset(train_x, train_y)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataset = torch.utils.data.TensorDataset(val_x, val_y)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# setup logging so that you can follow training using TensorBoard (see https://pytorch.org/docs/stable/tensorboard.html)\n",
        "writer = SummaryWriter()\n",
        "num_epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gskr8lq7Lzz8"
      },
      "outputs": [],
      "source": [
        "#cross entropy bcs of classfication task\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHw3EJ1xLzz8",
        "outputId": "c945eb7e-5e80-4a14-8d9b-778feb1e9b9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([256, 13])"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12px7wzULzz8",
        "outputId": "0af8a807-7a47-4181-aa73-e8326c115503"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([256, 61]), torch.Size([256, 61]))"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels.shape,outputs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nDayPtaLzz8"
      },
      "source": [
        "training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgNu5OgBLzz8"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-7hiV5DLzz8",
        "outputId": "05de64d8-ecc5-4ffa-d9da-e562f49891cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: train_loss=0.03554472348002738, val_loss=0.031379877695545906,train_acc=60.15643029813476,val_acc=60.2350527320012\n",
            "Epoch 1: train_loss=0.030330557459931906, val_loss=0.02978066157823721,train_acc=60.2592704713834,val_acc=60.27253361910114\n",
            "Epoch 2: train_loss=0.029217865793314306, val_loss=0.029440218473731673,train_acc=60.287193746981956,val_acc=60.284047099413215\n",
            "Epoch 3: train_loss=0.02859272443158001, val_loss=0.02928777032198515,train_acc=60.303199901945874,val_acc=60.28952286360251\n",
            "Epoch 4: train_loss=0.028193813928374268, val_loss=0.028711535262386238,train_acc=60.31481134179099,val_acc=60.30336256354631\n",
            "Epoch 5: train_loss=0.027883650424873146, val_loss=0.02862511327751853,train_acc=60.32328623092633,val_acc=60.30909970072793\n",
            "Epoch 6: train_loss=0.027631392649302207, val_loss=0.028204865034133893,train_acc=60.32954161172042,val_acc=60.32139730001699\n",
            "Epoch 7: train_loss=0.027437137209612647, val_loss=0.02835233763084563,train_acc=60.33488733373992,val_acc=60.31805172571518\n",
            "Epoch 8: train_loss=0.02725153962656098, val_loss=0.02847935869374054,train_acc=60.34010753466228,val_acc=60.311425920359646\n",
            "Epoch 9: train_loss=0.02712018992220256, val_loss=0.027933187278168257,train_acc=60.34381409882497,val_acc=60.32727819234439\n",
            "Epoch 10: train_loss=0.026976683171949345, val_loss=0.028203978349632244,train_acc=60.347402525484476,val_acc=60.32181549680472\n",
            "Epoch 11: train_loss=0.026886054093063588, val_loss=0.028172648382563156,train_acc=60.35037516040858,val_acc=60.325474718697315\n",
            "Epoch 12: train_loss=0.026777404491960203, val_loss=0.02807023466399631,train_acc=60.35282208344347,val_acc=60.326363386871236\n",
            "Epoch 13: train_loss=0.026670706949661976, val_loss=0.028056150227535926,train_acc=60.35535022601181,val_acc=60.32689920150551\n",
            "Epoch 14: train_loss=0.026602595056011286, val_loss=0.027786703953164377,train_acc=60.35809396952348,val_acc=60.333917066349535\n",
            "Epoch 15: train_loss=0.026523264614677546, val_loss=0.028120632281832172,train_acc=60.36074024959501,val_acc=60.32296553797096\n",
            "Epoch 16: train_loss=0.02646221138538338, val_loss=0.027707790703603057,train_acc=60.361392959300154,val_acc=60.335158588063095\n",
            "Epoch 17: train_loss=0.026389333853039394, val_loss=0.02793035320750746,train_acc=60.3640672970287,val_acc=60.33122492452855\n",
            "Epoch 18: train_loss=0.02633169286926084, val_loss=0.027923640682919568,train_acc=60.36532693815649,val_acc=60.332819299781754\n",
            "Epoch 19: train_loss=0.026277758914395037, val_loss=0.02786696649601926,train_acc=60.36637688521613,val_acc=60.333368183065645\n",
            "Epoch 20: train_loss=0.026214211750046852, val_loss=0.027702037414791294,train_acc=60.36880165746917,val_acc=60.338647917510684\n",
            "Epoch 21: train_loss=0.026162891897778276, val_loss=0.028137188747425542,train_acc=60.37044967563872,val_acc=60.329695892523425\n",
            "Epoch 22: train_loss=0.026135299881443908, val_loss=0.027955505498575926,train_acc=60.3707597865846,val_acc=60.33244030894288\n",
            "Epoch 23: train_loss=0.026083085887335444, val_loss=0.02784400958611465,train_acc=60.37247721053728,val_acc=60.33454436153112\n",
            "Epoch 24: train_loss=0.026035551279234067, val_loss=0.028055054163653715,train_acc=60.3738800933877,val_acc=60.33223121054901\n",
            "Epoch 25: train_loss=0.02601187943002662, val_loss=0.027737165125317396,train_acc=60.37395392932719,val_acc=60.33741946444674\n",
            "Epoch 26: train_loss=0.02596131424264508, val_loss=0.02766362972165081,train_acc=60.37523276779926,val_acc=60.34281681673833\n",
            "Epoch 27: train_loss=0.02592644260281303, val_loss=0.027832449694167212,train_acc=60.375690550624135,val_acc=60.33727570930096\n",
            "Epoch 28: train_loss=0.025878596527773363, val_loss=0.028229848656143034,train_acc=60.37809169537654,val_acc=60.3284020962114\n",
            "Epoch 29: train_loss=0.025862747868105836, val_loss=0.027972100867911624,train_acc=60.37823346038037,val_acc=60.337105816855946\n",
            "Epoch 30: train_loss=0.025828158134037278, val_loss=0.02814865511153703,train_acc=60.378877309772776,val_acc=60.33048001150041\n",
            "Epoch 31: train_loss=0.02577837216600063, val_loss=0.02812273413048789,train_acc=60.380012906522225,val_acc=60.33068910989427\n",
            "Epoch 32: train_loss=0.025765859770289872, val_loss=0.02811997282913696,train_acc=60.38114554983409,val_acc=60.330819796390436\n",
            "Epoch 33: train_loss=0.02574739656199007, val_loss=0.027950660811494225,train_acc=60.381172130772306,val_acc=60.33872632940838\n",
            "Epoch 34: train_loss=0.025719502249366845, val_loss=0.027751812276844694,train_acc=60.381944454699436,val_acc=60.34375775951071\n",
            "Epoch 35: train_loss=0.02568918907076002, val_loss=0.027782418375778755,train_acc=60.38367221568364,val_acc=60.34337876867183\n",
            "Epoch 36: train_loss=0.02563915428945077, val_loss=0.027782679736352584,train_acc=60.38452280570663,val_acc=60.33990250787386\n",
            "Epoch 37: train_loss=0.02562087794906294, val_loss=0.027718545580874616,train_acc=60.38570270401978,val_acc=60.34519531096852\n",
            "Epoch 38: train_loss=0.02562010521289194, val_loss=0.027921004624208778,train_acc=60.38534238463504,val_acc=60.3390530456488\n",
            "Epoch 39: train_loss=0.025580967837908367, val_loss=0.028049081155911936,train_acc=60.386792522486736,val_acc=60.33417843934186\n",
            "Epoch 40: train_loss=0.025573019412501258, val_loss=0.027873898333056913,train_acc=60.38651489935423,val_acc=60.34130085338282\n",
            "Epoch 41: train_loss=0.025549197895478784, val_loss=0.027802112487372146,train_acc=60.38742012797245,val_acc=60.344750976881556\n",
            "Epoch 42: train_loss=0.025534027709323434, val_loss=0.027685541633117858,train_acc=60.38778340079477,val_acc=60.3474039127537\n",
            "Epoch 43: train_loss=0.02551979341205724, val_loss=0.028044887133142023,train_acc=60.38865909503719,val_acc=60.3378637985337\n",
            "Epoch 44: train_loss=0.025490161860187436, val_loss=0.027718464766059034,train_acc=60.38870044316331,val_acc=60.34285602268717\n",
            "Epoch 45: train_loss=0.025480351986568065, val_loss=0.02776065412721905,train_acc=60.38937382693151,val_acc=60.346358420784384\n",
            "Epoch 46: train_loss=0.025464590535024076, val_loss=0.027953955073868948,train_acc=60.38956875381178,val_acc=60.33653079627282\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[149], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m correct_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      7\u001b[0m correct_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m      9\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n",
            "File \u001b[1;32md:\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32md:\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
            "File \u001b[1;32md:\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:172\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    169\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [default_collate(samples) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[1;32md:\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:172\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    169\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[1;32md:\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:138\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    136\u001b[0m         storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_new_shared(numel)\n\u001b[0;32m    137\u001b[0m         out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr_\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring_\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndarray\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemmap\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# array of string classes and object\u001b[39;00m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    net.train()\n",
        "    train_loss = 0.0\n",
        "    total_train = 0\n",
        "    total_val = 0\n",
        "    correct_train = 0\n",
        "    correct_val = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device).float()\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # accumulate the training loss\n",
        "        train_loss += loss.item()\n",
        "        #training accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predicted = F.one_hot(predicted,num_classes=output_dim) #make it one-hot to be able to compare with labels\n",
        "\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "    # calculate the validation loss\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0.0\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device).float()\n",
        "\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            #validation accuracy\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predicted = F.one_hot(predicted,num_classes=output_dim) #make it one-hot to be able to compare with labels\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    # print the epoch loss\n",
        "    train_loss /= len(train_loader)\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    train_acc = correct_train / total_train\n",
        "    val_acc = correct_val / total_val\n",
        "\n",
        "    print(f'Epoch {epoch}: train_loss={train_loss}, val_loss={val_loss},train_acc={train_acc},val_acc={val_acc}')\n",
        "    writer.add_scalars('loss',{'train':train_loss,'val':val_loss},epoch)\n",
        "    writer.add_scalars('accuracy',{'train':train_acc,'val':val_acc},epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGi8P5_pLzz9"
      },
      "source": [
        "evaluate on testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrXdPhksLzz9",
        "outputId": "030d7908-176c-4c0f-c17f-1d22a6578c04"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_14084\\4202707494.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_x = torch.tensor(test_x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_loss=0.0030446433670637692,test_acc=60.27842758007815\n"
          ]
        }
      ],
      "source": [
        "test_x = torch.tensor(test_x)\n",
        "test_dataset = torch.utils.data.TensorDataset(test_x, test_y)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "net.eval()\n",
        "total_test = 0\n",
        "correct_test = 0\n",
        "with torch.no_grad():\n",
        "    test_loss = 0.0\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device).float()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        #test accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predicted = F.one_hot(predicted,num_classes=output_dim) #make it one-hot to be able to compare with labels\n",
        "        total_test += labels.size(0)\n",
        "        correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "test_acc = correct_test / total_test\n",
        "\n",
        "print(f'test_loss={test_loss},test_acc={test_acc}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF2Km1aULzz9"
      },
      "source": [
        "save the trained network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGq1nSwSLzz9"
      },
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), 'first_net_1_epoch_42.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuJ_thiALzz-"
      },
      "source": [
        "# experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml25GkX7Lzz-"
      },
      "source": [
        "## experiment 1\n",
        "- ADAM with BCEWithLogitsLoss\n",
        "- loss started at around 0.03 and didnt improve basically at all\n",
        "accuracy was ca 60.3% for both validation and training\n",
        "- test error ca 0.03 and test accuracy ca 60.3%\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWRP74lLzz-"
      },
      "source": [
        "## experiment 2\n",
        "![image.png](attachment:image.png)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dt2119",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
