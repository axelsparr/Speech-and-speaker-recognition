{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lab3_proto import *\n",
    "#from proto2 import *\n",
    "from lab3_proto import *\n",
    "from lab3_tools import *\n",
    "from lab2_proto import *\n",
    "from lab2_tools import *\n",
    "from lab1_proto import *\n",
    "from lab1_tools import *\n",
    "from IPython.display import Audio,Image\n",
    "from scipy.signal import lfilter\n",
    "from prondict import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first time setup: download tidigits to this folder using this link: https://drive.google.com/file/d/1UgY60Uek1OznD7VGRFyOiF_eqwSVvhM3/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('woman', 'ac', 'z849768', 'a')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path2info('tidigits/disc_4.1.1/tidigits/train/woman/ac/z849768a.wav') #'tidigits/disc_4.1.1/tidigits/train/man/ae/z9z6531a.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('man', 'ae', 'z9z6531', 'a')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path2info('tidigits\\\\disc_4.1.1\\\\tidigits\\\\train\\\\man\\\\ae\\\\z9z6531a.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 8, 10, 10, ..., 14, 14, 10], dtype=int16), 20000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "loadAudio(\"C:\\\\Users\\\\A\\\\Desktop\\\\KTH\\\\dt2119_speech_recpgmotopm\\\\Speech-and-speaker-recognition\\\\lab3\\\\tidigits\\\\tidigits\\\\disc_4.1.1\\\\tidigits\\\\train\\\\man\\\\ae\\\\1a.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "base_path = Path(\"C:\\\\Users\\\\A\\\\Desktop\\\\KTH\\\\dt2119_speech_recpgmotopm\\\\Speech-and-speaker-recognition\\\\lab3\\\\tidigits\\\\\")\n",
    "filename = 'tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
    "filepath = base_path / Path(filename)\n",
    "samples, samplingrate = loadAudio(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ah_0',\n",
       " 'ah_1',\n",
       " 'ah_2',\n",
       " 'ao_0',\n",
       " 'ao_1',\n",
       " 'ao_2',\n",
       " 'ay_0',\n",
       " 'ay_1',\n",
       " 'ay_2',\n",
       " 'eh_0',\n",
       " 'eh_1',\n",
       " 'eh_2',\n",
       " 'ey_0',\n",
       " 'ey_1',\n",
       " 'ey_2',\n",
       " 'f_0',\n",
       " 'f_1',\n",
       " 'f_2',\n",
       " 'ih_0',\n",
       " 'ih_1',\n",
       " 'ih_2',\n",
       " 'iy_0',\n",
       " 'iy_1',\n",
       " 'iy_2',\n",
       " 'k_0',\n",
       " 'k_1',\n",
       " 'k_2',\n",
       " 'n_0',\n",
       " 'n_1',\n",
       " 'n_2',\n",
       " 'ow_0',\n",
       " 'ow_1',\n",
       " 'ow_2',\n",
       " 'r_0',\n",
       " 'r_1',\n",
       " 'r_2',\n",
       " 's_0',\n",
       " 's_1',\n",
       " 's_2',\n",
       " 'sil_0',\n",
       " 'sil_1',\n",
       " 'sil_2',\n",
       " 'sp_0',\n",
       " 't_0',\n",
       " 't_1',\n",
       " 't_2',\n",
       " 'th_0',\n",
       " 'th_1',\n",
       " 'th_2',\n",
       " 'uw_0',\n",
       " 'uw_1',\n",
       " 'uw_2',\n",
       " 'v_0',\n",
       " 'v_1',\n",
       " 'v_2',\n",
       " 'w_0',\n",
       " 'w_1',\n",
       " 'w_2',\n",
       " 'z_0',\n",
       " 'z_1',\n",
       " 'z_2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneHMMs = np.load('lab2_models_all.npz',allow_pickle=True)['phoneHMMs'].item()\n",
    "phones = sorted(phoneHMMs.keys())\n",
    "nstates = {phone: phoneHMMs[phone]['means'].shape[0] for phone in phones}\n",
    "stateList = [ph + '_' + str(id) for ph in phones for id in range(nstates[ph])]\n",
    "stateList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateList.index('ay_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
    "samples, samplingrate = loadAudio(base_path / Path(filename))\n",
    "\n",
    "lmfcc = mfcc(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = np.load(\"lab3_example.npz\",allow_pickle=True)['example'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
    "samples, samplingrate = loadAudio(base_path / Path(filename))\n",
    "lmfcc = mfcc(samples)\n",
    "wordTrans = list(path2info(filename)[2])\n",
    "phoneTrans = words2phones(wordTrans,prondict)\n",
    "utteranceHMM = concatHMMs(phoneHMMs,phoneTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans \n",
    "              for stateid in range(nstates[phone])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r_1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateTrans[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_21468\\1985007783.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  score,path=viterbi(log_likelihoods,np.log(Hmm[\"startprob\"]),np.log(Hmm[\"transmat\"]),False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sil_0',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_2',\n",
       " 'z_0',\n",
       " 'z_0',\n",
       " 'z_0',\n",
       " 'z_0',\n",
       " 'z_1',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_1',\n",
       " 'iy_2',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_1',\n",
       " 'r_2',\n",
       " 'ow_0',\n",
       " 'ow_1',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'f_0',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_2',\n",
       " 'ao_0',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_1',\n",
       " 'r_2',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_1',\n",
       " 'th_1',\n",
       " 'th_1',\n",
       " 'th_2',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_1',\n",
       " 'r_2',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_1',\n",
       " 'iy_1',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_1',\n",
       " 'sil_2']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#align the states in the utteranceHMM model to the sequence of feature vectors in lmfcc\n",
    "\n",
    "X0 = lmfcc\n",
    "Hmm = utteranceHMM\n",
    "log_likelihoods=log_multivariate_normal_density_diag(X0,Hmm[\"means\"],Hmm[\"covars\"])\n",
    "score,path=viterbi(log_likelihoods,np.log(Hmm[\"startprob\"]),np.log(Hmm[\"transmat\"]),False)\n",
    "state_seq = []\n",
    "for i in range(len(path)):\n",
    "    state_seq.append(stateTrans[path[i]])\n",
    "state_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  2,  3,  3,  3,  3,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  7,  8,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9, 10, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "       14, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 19, 20, 20,\n",
       "       20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21,\n",
       "       21, 21, 21, 21, 21, 21, 22, 22, 22, 23, 24, 26, 26, 26, 26, 26, 26,\n",
       "       26, 26, 26, 26, 27, 27, 27, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "       30, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 34, 34, 34,\n",
       "       34, 34, 34, 34, 34, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "       36, 36, 36, 36, 36, 36, 37, 38], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 0.01 sil_0\\n0.01 0.19000000000000003 sil_1\\n0.19000000000000003 0.20000000000000004 sil_2\\n0.20000000000000004 0.24000000000000007 z_0\\n0.24000000000000007 0.25000000000000006 z_1\\n0.25000000000000006 0.36000000000000015 z_2\\n0.36000000000000015 0.4400000000000002 iy_0\\n0.4400000000000002 0.45000000000000023 iy_1\\n0.45000000000000023 0.46000000000000024 iy_2\\n0.46000000000000024 0.5600000000000003 r_0\\n0.5600000000000003 0.5700000000000003 r_1\\n0.5700000000000003 0.5800000000000003 r_2\\n0.5800000000000003 0.5900000000000003 ow_0\\n0.5900000000000003 0.6000000000000003 ow_1\\n0.6000000000000003 0.6900000000000004 ow_2\\n0.6900000000000004 0.7000000000000004 f_0\\n0.7000000000000004 0.8100000000000005 f_1\\n0.8100000000000005 0.8200000000000005 f_2\\n0.8200000000000005 0.8300000000000005 ao_0\\n0.8300000000000005 0.9700000000000006 ao_1\\n0.9700000000000006 1.0800000000000007 ao_2\\n1.0800000000000007 1.1100000000000008 r_0\\n1.1100000000000008 1.1200000000000008 r_1\\n1.1200000000000008 1.1300000000000008 r_2\\n1.1300000000000008 1.2300000000000009 th_0\\n1.2300000000000009 1.260000000000001 th_1\\n1.260000000000001 1.270000000000001 th_2\\n1.270000000000001 1.360000000000001 r_0\\n1.360000000000001 1.370000000000001 r_1\\n1.370000000000001 1.380000000000001 r_2\\n1.380000000000001 1.480000000000001 iy_0\\n1.480000000000001 1.500000000000001 iy_1\\n1.500000000000001 1.5800000000000012 iy_2\\n1.5800000000000012 1.7600000000000013 sil_0\\n1.7600000000000013 1.7700000000000014 sil_1\\n1.7700000000000014 1.7800000000000014 sil_2\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take state_seq and create a transcription file based on it\n",
    "#[sil_0,sil_1,sil_1,z_0,z_1,z_2...] -> \"z\" at 40 ms\n",
    "frames2trans(state_seq, outfilename='z43a.lab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the alignment is mostly good but some parts bleed in to each other e.g. \"r\" in four"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateList.index(\"ah_0\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_21468\\163461277.py:22: RuntimeWarning: divide by zero encountered in log\n",
      "  score,path=viterbi(log_likelihoods,np.log(Hmm[\"startprob\"]),np.log(Hmm[\"transmat\"]),False)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "if not Path(\"traindata.npz\").exists():\n",
    "    traindata = []\n",
    "    for root, dirs, files in os.walk(base_path / 'tidigits/disc_4.1.1/tidigits/train'):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                filename = os.path.join(root, file)\n",
    "                samples, samplingrate = loadAudio(filename)\n",
    "                \n",
    "                mspec_vals = mspec(samples)\n",
    "\n",
    "                lmfcc = mfcc(samples)\n",
    "                wordTrans = list(path2info(filename)[2])\n",
    "                #phoneHMM har vi redan\n",
    "                phoneTrans = words2phones(wordTrans,prondict)\n",
    "                utteranceHMM = concatHMMs(phoneHMMs,phoneTrans)\n",
    "                stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans \n",
    "                                for stateid in range(nstates[phone])]\n",
    "                Hmm = utteranceHMM\n",
    "                log_likelihoods=log_multivariate_normal_density_diag(lmfcc,Hmm[\"means\"],Hmm[\"covars\"])\n",
    "                score,path=viterbi(log_likelihoods,np.log(Hmm[\"startprob\"]),np.log(Hmm[\"transmat\"]),False)\n",
    "                \n",
    "                state_seq = []\n",
    "                for i in range(len(path)):\n",
    "                    state_seq.append(stateTrans[path[i]])\n",
    "                \n",
    "\n",
    "                traindata.append({'filename': filename, 'lmfcc': lmfcc,\n",
    "                    'mspec': mspec_vals, 'targets': state_seq})\n",
    "    np.savez('traindata.npz', traindata=traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_21468\\272016922.py:20: RuntimeWarning: divide by zero encountered in log\n",
      "  score,path=viterbi(log_likelihoods,np.log(Hmm[\"startprob\"]),np.log(Hmm[\"transmat\"]),False)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not Path(\"testndata.npz\").exists():\n",
    "    testdata = []\n",
    "    for root, dirs, files in os.walk(base_path / 'tidigits/disc_4.2.1/tidigits/test'):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                filename = os.path.join(root, file)\n",
    "                samples, samplingrate = loadAudio(filename)\n",
    "                \n",
    "                mspec_vals = mspec(samples)\n",
    "\n",
    "                lmfcc = mfcc(samples)\n",
    "                wordTrans = list(path2info(filename)[2])\n",
    "                phoneTrans = words2phones(wordTrans,prondict)\n",
    "                utteranceHMM = concatHMMs(phoneHMMs,phoneTrans)\n",
    "                stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans \n",
    "                                for stateid in range(nstates[phone])]\n",
    "                Hmm = utteranceHMM\n",
    "                log_likelihoods=log_multivariate_normal_density_diag(lmfcc,Hmm[\"means\"],Hmm[\"covars\"])\n",
    "                score,path=viterbi(log_likelihoods,np.log(Hmm[\"startprob\"]),np.log(Hmm[\"transmat\"]),False)\n",
    "                \n",
    "                state_seq = []\n",
    "                for i in range(len(path)):\n",
    "                    state_seq.append(stateTrans[path[i]])\n",
    "                \n",
    "\n",
    "                testdata.append({'filename': filename, 'lmfcc': lmfcc,\n",
    "                    'mspec': mspec_vals, 'targets': state_seq})\n",
    "    np.savez('testdata.npz', testdata=testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('testdata.npz', testdata=testdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = np.load(\"traindata.npz\",allow_pickle=True)['traindata']\n",
    "testdata = np.load(\"testdata.npz\",allow_pickle=True)['testdata']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4235, 4388)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "males = []\n",
    "females = []\n",
    "for i in range(len(traindata)):\n",
    "    speaker_gender = path2info(traindata[i][\"filename\"])[0]\n",
    "    if speaker_gender == \"man\":\n",
    "        males.append(traindata[i])\n",
    "    else:\n",
    "        females.append(traindata[i])\n",
    "len(males),len(females)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "train_size_male = int(0.9 * len(males))\n",
    "train_size_female = int(0.9 * len(females))\n",
    "\n",
    "random.shuffle(males)\n",
    "random.shuffle(females)\n",
    "#extract the amount of males we need\n",
    "train_males = males[:train_size_male]\n",
    "val_males = males[train_size_male:]\n",
    "#females we need\n",
    "train_females = females[:train_size_female]\n",
    "val_females = females[train_size_female:]\n",
    "#merge them\n",
    "train_data = train_males + train_females\n",
    "val_data = val_males + val_females\n",
    "#shuffle again to avoid it being MMMM...FFFF... instead MFMFFMFM...\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male to female ratio is 0.9650544441630793\n",
      "male to female ratio is 0.9658314350797267\n"
     ]
    }
   ],
   "source": [
    "#check gender ratio\n",
    "for k in [train_data,val_data]:\n",
    "    male = 0\n",
    "    female = 0\n",
    "    for i in range(len(k)):\n",
    "        speaker_gender = path2info(k[i][\"filename\"])[0]\n",
    "        if speaker_gender == \"man\":\n",
    "            male += 1\n",
    "        else:\n",
    "            female +=1\n",
    "    print(f\"male to female ratio is {male/female}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata=train_data\n",
    "valdata=val_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(i,length):\n",
    "    idx_list = list(range(length))\n",
    "    idx_list = idx_list[1:4][::-1] + idx_list + idx_list[-4:-1][::-1]\n",
    "    return idx_list[i:i + 7]\n",
    "for dataset in [traindata, valdata,testdata]:\n",
    "    for i in range(len(dataset)):\n",
    "        #Tx91, where T is number of frames in the datapoint\n",
    "        datapoint_dynamic = np.zeros((len(dataset[i][\"lmfcc\"]),7*dataset[i][\"lmfcc\"].shape[1]))#a new matrix that stores the stacked (dynamic) data of dataset[i]\n",
    "        for t in range(len(dataset[i])):\n",
    "            indxs = get_indices(t,len(dataset[i]))\n",
    "            for k in indxs:\n",
    "                datapoint_dynamic[t,13*k:13*(k+1)] = dataset[i][\"lmfcc\"][k] #1x13\n",
    "\n",
    "        dataset[i][\"lmfcc_dynamic\"] = datapoint_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((193, 91), (193, 13))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata[2][\"lmfcc_dynamic\"].shape,traindata[2][\"lmfcc\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dynamic version of mspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [traindata, valdata,testdata]:\n",
    "    for i in range(len(dataset)):\n",
    "        #Tx91, where T is number of frames in the datapoint\n",
    "        datapoint_dynamic = np.zeros((len(dataset[i][\"mspec\"]),7*dataset[i][\"mspec\"].shape[1]))#a new matrix that stores the stacked (dynamic) data of dataset[i]\n",
    "        for t in range(len(dataset[i])):\n",
    "            indxs = get_indices(t,len(dataset[i]))\n",
    "            for k in indxs:\n",
    "                datapoint_dynamic[t,40*k:40*(k+1)] = dataset[i][\"mspec\"][k] #1x13\n",
    "\n",
    "        dataset[i][\"mspec_dynamic\"] = datapoint_dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create our big matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmfcc_train_x=np.concatenate([d[\"lmfcc\"] for d in traindata])\n",
    "lmfcc_val_x=np.concatenate([d[\"lmfcc\"] for d in valdata])\n",
    "lmfcc_test_x=np.concatenate([d[\"lmfcc\"] for d in testdata])\n",
    "\n",
    "lmfcc_train_x_dynamic = np.concatenate([d[\"lmfcc_dynamic\"] for d in traindata])\n",
    "lmfcc_val_x_dynamic=np.concatenate([d[\"lmfcc_dynamic\"] for d in valdata])\n",
    "lmfcc_test_x_dynamic=np.concatenate([d[\"lmfcc_dynamic\"] for d in testdata])\n",
    "\n",
    "\n",
    "mspec_train_x = np.concatenate([d[\"mspec\"] for d in traindata]) \n",
    "mspec_val_x = np.concatenate([d[\"mspec\"] for d in valdata]) \n",
    "mspec_test_x = np.concatenate([d[\"mspec\"] for d in testdata]) \n",
    "\n",
    "\n",
    "mspec_train_x_dynamic = np.concatenate([d[\"mspec_dynamic\"] for d in traindata]) \n",
    "mspec_val_x_dynamic = np.concatenate([d[\"mspec_dynamic\"] for d in valdata]) \n",
    "mspec_test_x_dynamic = np.concatenate([d[\"mspec_dynamic\"] for d in testdata]) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dt2119",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
