{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lab3_proto import *\n",
    "#from proto2 import *\n",
    "from lab3_proto import *\n",
    "from lab3_tools import *\n",
    "from lab2_proto import *\n",
    "from lab2_tools import *\n",
    "from lab1_proto import *\n",
    "from lab1_tools import *\n",
    "from IPython.display import Audio,Image\n",
    "from scipy.signal import lfilter\n",
    "from prondict import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('woman', 'ac', 'z849768', 'a')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path2info('tidigits/disc_4.1.1/tidigits/train/woman/ac/z849768a.wav') #'tidigits/disc_4.1.1/tidigits/train/man/ae/z9z6531a.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('man', 'ae', 'z9z6531', 'a')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path2info('tidigits/disc_4.1.1/tidigits/train/man/ae/z9z6531a.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10.99966431, 12.99960327, 10.99966431, ...,  8.99972534,\n",
       "         8.99972534,  8.99972534]),\n",
       " 20000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadAudio('tidigits/disc_4.1.1/tidigits/train/man/ae/z9z6531a.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
    "samples, samplingrate = loadAudio(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ah_0',\n",
       " 'ah_1',\n",
       " 'ah_2',\n",
       " 'ao_0',\n",
       " 'ao_1',\n",
       " 'ao_2',\n",
       " 'ay_0',\n",
       " 'ay_1',\n",
       " 'ay_2',\n",
       " 'eh_0',\n",
       " 'eh_1',\n",
       " 'eh_2',\n",
       " 'ey_0',\n",
       " 'ey_1',\n",
       " 'ey_2',\n",
       " 'f_0',\n",
       " 'f_1',\n",
       " 'f_2',\n",
       " 'ih_0',\n",
       " 'ih_1',\n",
       " 'ih_2',\n",
       " 'iy_0',\n",
       " 'iy_1',\n",
       " 'iy_2',\n",
       " 'k_0',\n",
       " 'k_1',\n",
       " 'k_2',\n",
       " 'n_0',\n",
       " 'n_1',\n",
       " 'n_2',\n",
       " 'ow_0',\n",
       " 'ow_1',\n",
       " 'ow_2',\n",
       " 'r_0',\n",
       " 'r_1',\n",
       " 'r_2',\n",
       " 's_0',\n",
       " 's_1',\n",
       " 's_2',\n",
       " 'sil_0',\n",
       " 'sil_1',\n",
       " 'sil_2',\n",
       " 'sp_0',\n",
       " 't_0',\n",
       " 't_1',\n",
       " 't_2',\n",
       " 'th_0',\n",
       " 'th_1',\n",
       " 'th_2',\n",
       " 'uw_0',\n",
       " 'uw_1',\n",
       " 'uw_2',\n",
       " 'v_0',\n",
       " 'v_1',\n",
       " 'v_2',\n",
       " 'w_0',\n",
       " 'w_1',\n",
       " 'w_2',\n",
       " 'z_0',\n",
       " 'z_1',\n",
       " 'z_2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneHMMs = np.load('lab2_models_all.npz',allow_pickle=True)['phoneHMMs'].item()\n",
    "phones = sorted(phoneHMMs.keys())\n",
    "nstates = {phone: phoneHMMs[phone]['means'].shape[0] for phone in phones}\n",
    "stateList = [ph + '_' + str(id) for ph in phones for id in range(nstates[ph])]\n",
    "stateList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateList.index('ay_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
    "samples, samplingrate = loadAudio(filename)\n",
    "\n",
    "lmfcc = mfcc(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m wordTrans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(path2info(filename)[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m      5\u001b[0m phoneTrans \u001b[38;5;241m=\u001b[39m words2phones(wordTrans,prondict)\n\u001b[0;32m----> 6\u001b[0m utteranceHMM \u001b[38;5;241m=\u001b[39m \u001b[43mconcatHMMs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphoneHMMs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mphoneTrans\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/cornelia/DT2119 - Speech and Speaker Recognition/lab3/lab2_proto.py:106\u001b[0m, in \u001b[0;36mconcatHMMs\u001b[0;34m(hmmmodels, namelist)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcatHMMs\u001b[39m(hmmmodels, namelist):\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Concatenates HMM models in a left to right manner\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m       wordHMMs['o'] = concatHMMs(phoneHMMs, ['sil', 'ow', 'sil'])\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     concat \u001b[38;5;241m=\u001b[39m hmmmodels[\u001b[43mnamelist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(namelist)):\n\u001b[1;32m    108\u001b[0m         concat \u001b[38;5;241m=\u001b[39m concatTwoHMMs(concat, hmmmodels[namelist[idx]])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "filename = 'tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
    "samples, samplingrate = loadAudio(filename)\n",
    "lmfcc = mfcc(samples)\n",
    "wordTrans = list(path2info(filename)[2])\n",
    "phoneTrans = words2phones(wordTrans,prondict)\n",
    "utteranceHMM = concatHMMs(phoneHMMs,phoneTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordTrans = list(path2info(filename)[2])\n",
    "wordTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordHMMs = {}\n",
    "wordHMMs['o'] = concatHMMs(phoneHMMs, isolated['o'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from prondict import prondict\n",
    "phoneTrans = words2phones(wordTrans, prondict)\n",
    "phoneTrans\n",
    "print(phoneTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab2_proto import concatHMMs\n",
    "phoneHMMs = np.load('lab2_models_all.npz', allow_pickle=True)['phoneHMMs'].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utteranceHMM = concatHMMs(phoneHMMs, phoneTrans) \n",
    "utteranceHMM['transmat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans \n",
    "              for stateid in range(nstates[phone])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateTrans[10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dt2119",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
